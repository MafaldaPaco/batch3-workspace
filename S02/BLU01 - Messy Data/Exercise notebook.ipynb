{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1b6b75485105e36c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# BLU01 - Exercises Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-26d8a5f531043e66",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Important Note**\n",
    "\n",
    "When reading files, please use `os.path.join()`. Specially if you are a Windows user!\n",
    "The grader is running on Linux, reading a file my be running locally for you, but then don't run in the grader because of all the weird backslashes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0240afddd4fae69d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import chardet\n",
    "import hashlib # for grading purposes\n",
    "import math\n",
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-93e0b4e1a40ebaaa",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Q1: Use a shell command to keep in 2 variables the first third and the last third of the lines existent in a file\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-05a3d2245d57305d",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "# Use the file data/exercises/elon_musk.txt\n",
    "# Start by counting the total lines and add the total to the variable count_total.  \n",
    "! wc -l < data/exercises/elon_musk.txt \n",
    "count_total=18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-2e69c6137e73d90c",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "expected_hash = '4ec9599fc203d176a301536c2e091a19bc852759b255bd6818810a42c5fed14a'\n",
    "assert hashlib.sha256(str(count_total).encode()).hexdigest() == expected_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-14cf2619322a8763",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-eb7be6620cea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# first_third = ...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# YOUR CODE HERE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# last_third = ...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# NOT GRADED optional exercise!!\n",
    "# Now add the first third and the last third of the lines to the variables first_third and last_third. \n",
    "# Make it work to any files using count_total/3 for instance in the bash commands\n",
    "# first_third = ...\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# last_third = ...\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a6556340d1db98d7",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Test the `first_third` and `last_third` exercise by running the following (ungraded) asserts.\n",
    "\n",
    "```\n",
    "assert first_third[-1][0] == 'H'\n",
    "assert last_third[0][0] == 'N'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e27cb8588bb5fd40",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Q2: Read a file with specific delimiter\n",
    "\n",
    "Read file **data/exercises/euribor_interest_rates.csv** into a pandas DataFrame.\n",
    "\n",
    "First, you should preview the file using a shell command in order to find out the used delimiter, and other properties of this file.\n",
    "\n",
    "Then, you should use function read_csv to read the data into a DataFrame. The resulting DataFrame should have the last column as index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-942e0590467e20d9",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euribor 3 months|Euribor 6 months|Euribor 12 months|Years\n",
      "3,34|3,52|3,88|1999\n",
      "4,86|4,83|4,75|2000\n",
      "3,29|3,26|3,34|2001\n",
      "2,87|2,80|2,75|2002\n",
      "2,12|2,17|2,31|2003\n",
      "2,16|2,22|2,36|2004\n",
      "2,49|2,64|2,84|2005\n",
      "3,73|3,85|4,03|2006\n",
      "4,68|4,71|4,75|2007\n",
      "2,89|2,97|3,05|2008\n",
      "0,70|0,99|1,25|2009\n",
      "1,01|1,23|1,51|2010\n",
      "1,36|1,62|1,95|2011\n",
      "0,19|0,32|0,54|2012\n",
      "0,29|0,39|0,56|2013\n",
      "0,08|0,17|0,33|2014\n",
      "-0,13|-0,04|0,06|2015\n",
      "-0,32|-0,22|-0,08|2016\n",
      "-0,33|-0,27|-0,19|2017\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Use a shell command to preview the data\n",
    "! cat data/exercises/euribor_interest_rates.csv\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Use function read_csv to read the data into a DataFrame\n",
    "df2 = pd.read_csv(os.path.join('data', 'exercises', 'euribor_interest_rates.csv'), sep='|', index_col=-1, decimal=',')\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-0c275c9acaa9c74d",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert df2.loc[2001, 'Euribor 3 months'] == 3.29\n",
    "assert set(df2.columns) == {'Euribor 3 months', 'Euribor 6 months', 'Euribor 12 months'}\n",
    "assert len(df2) == 19\n",
    "assert df2.index[0] == 1999\n",
    "\n",
    "expected_hash = 'b68ca0811f132f73edc68e9d3bebb288ef036c1fef8aabe6d2c63a2b6bfa859c'\n",
    "assert hashlib.sha256(df2.index.name.encode()).hexdigest() == expected_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f6f9efef818e4a83",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Q3: Read a csv file with problems\n",
    "\n",
    "Read file **data/exercises/portugal_urban_waste_per_inhabitant.csv** using function `read_csv`. Pay attention to the following:\n",
    "* you might find some trouble when reading the file, at first, then just ignore the problems ;)\n",
    "* use the first column as index\n",
    "* there are some inputs in the file that should be interpreted as NaN, make sure you select the right one when reading the file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2771b707556c08d2",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Years,Urban waste collection per inhabitant (kg/inhabitant),Selective urban waste collection per inhabitant (kg/inhabitant)\n",
      "1989,no-data,no-data\n",
      "1990,480,78.2,1990,,\n",
      "1991,425.7,1.5\n",
      "1992,999999,1.7\n",
      "1993,357.6,2.3\n",
      "1994,999999,999999\n",
      "1995,352.0,4.0\n",
      "1996,371.7,5.3\n",
      "1997,397.0,6.6\n",
      "1998,413.2,8.1\n",
      "1999,433.3,10.6\n",
      "2000,457.2,15.3\n",
      "2001,454.4,18.3\n",
      "2002,441.0,20.4\n",
      "2003,448.7,21.7\n",
      "2004,445.0,30.5\n",
      "2005,451.8,40.5\n",
      "2006,465.5,48.1\n",
      "2007,471.1,54.6\n",
      "2008,518.3,60.3\n",
      "2009,520.1,66.5\n",
      "2010,516.1,76.2\n",
      "2011,490.4,71.4\n",
      "2012,453.3,63.3\n",
      "2013,439.7,56.3\n",
      "2014,452.9,61.4\n",
      "2015,460.4,70.8\n",
      "2016,460.9,75.1\n",
      "2017,480,78.2,,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 3: expected 3 fields, saw 6\\nSkipping line 30: expected 3 fields, saw 5\\n'\n"
     ]
    }
   ],
   "source": [
    "# Read file data/exercises/portugal_urban_waste_per_inhabitant.csv with read_csv\n",
    "! cat data/exercises/portugal_urban_waste_per_inhabitant.csv\n",
    "\n",
    "df3 = pd.read_csv(os.path.join('data', 'exercises', 'portugal_urban_waste_per_inhabitant.csv'), index_col= 0, na_values=['no-data', 999999.0], error_bad_lines=False)\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-601b354802964776",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.isnan(df3.loc[1994, 'Urban waste collection per inhabitant (kg/inhabitant)'])\n",
    "assert df3.loc[2011, 'Selective urban waste collection per inhabitant (kg/inhabitant)'] == 71.4\n",
    "\n",
    "mean_selective_waste = df3['Selective urban waste collection per inhabitant (kg/inhabitant)'].mean()\n",
    "assert math.isclose(35.632, mean_selective_waste, rel_tol=1e-3)\n",
    "\n",
    "expected_hash = 'b68ca0811f132f73edc68e9d3bebb288ef036c1fef8aabe6d2c63a2b6bfa859c'\n",
    "assert hashlib.sha256(df3.index.name.encode()).hexdigest() == expected_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5cfd5a97b1c49a0e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Q4: Repair a csv file after importing\n",
    "Read the same file **data/exercises/portugal_urban_waste_per_inhabitant.csv** using function `read_csv`. But now, be sure you don't miss any lines with relevant information! \n",
    "\n",
    "* use csv module to import everything to a list of lists\n",
    "* create a df with only 3 meaningful columns, where the `Years` should be index\n",
    "* replace garbage values with NaN's \n",
    "* format the columns with the right type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-119041388e17fb72",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Read file data/exercises/portugal_urban_waste_per_inhabitant.csv using  \n",
    "file= open(os.path.join('data', 'exercises', 'portugal_urban_waste_per_inhabitant.csv'), 'r')\n",
    "lines = list(csv.reader(file))\n",
    "# YOUR CODE HERE\n",
    "# create a dataframe using the line list with only 3 columns\n",
    "csv_list = [i[:3] for i in lines]\n",
    "file.close()\n",
    "df4 = pd.DataFrame(csv_list[1:], columns=csv_list[0])\n",
    "# YOUR CODE HERE\n",
    "\n",
    "#replace invalid values with nan (np.nan)\n",
    "df4= df4.replace(['no-data', '999999'], np.nan)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "#set types per dataframe column\n",
    "df4['Urban waste collection per inhabitant (kg/inhabitant)'] = df4['Urban waste collection per inhabitant (kg/inhabitant)'].astype(float)\n",
    "df4['Selective urban waste collection per inhabitant (kg/inhabitant)'] = df4['Selective urban waste collection per inhabitant (kg/inhabitant)'].astype(float)\n",
    "df4['Years']=df4['Years'].astype(int)\n",
    "# YOUR CODE HERE\n",
    "df4= df4.set_index('Years', drop=True)\n",
    "\n",
    "#set a new index to the dataframe\n",
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-a42299f9047590d5",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.isnan(df4.loc[1994, 'Urban waste collection per inhabitant (kg/inhabitant)'])\n",
    "assert df4.loc[2012, 'Selective urban waste collection per inhabitant (kg/inhabitant)'] == 63.3\n",
    "\n",
    "mean_selective_waste = df4['Selective urban waste collection per inhabitant (kg/inhabitant)'].mean()\n",
    "assert math.isclose(38.78518518518518, mean_selective_waste, rel_tol=1e-3)\n",
    "\n",
    "expected_hash = 'b68ca0811f132f73edc68e9d3bebb288ef036c1fef8aabe6d2c63a2b6bfa859c'\n",
    "assert hashlib.sha256(df4.index.name.encode()).hexdigest() == expected_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-389bc42fe462c70e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Q5: Read a JSON file\n",
    "\n",
    "Read file **data/exercises/portugal_production_of_electricity_gwh.json**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5c2125479f7e50e5",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Read file data/exercises/portugal_production_of_electricity_gwh.json with read_json\n",
    "df5 = pd.read_json(os.path.join('data', 'exercises', 'portugal_production_of_electricity_gwh.json'), orient='index')\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-3f085fa2cdad9319",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(df5) == 23\n",
    "assert set(df5.columns) == {'Biomass', 'Geothermal power', 'Hydropower < 10MW', 'Hydropower > 10MW', \n",
    "                           'Photovoltaic', 'Total','Total renewable sources','Windpower','Year'}\n",
    "\n",
    "expected_hash = 'c8226c54f1a24ae847c02a3e7a7d6e9fb44c2f82eb6f1fddcee9092c434e67fb'\n",
    "assert hashlib.sha256(str(df5.loc[:,'Hydropower > 10MW'].sum()).encode()).hexdigest() == expected_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4d4b970f55b3e427",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Q6: Read an Excel file\n",
    "\n",
    "Read file **data/exercises/portugal_gas_emissions_per_year.xlsx** using function read_excel. Pay attention to the following:\n",
    "\n",
    "* you should grab the table \"Series\" in sheet \"Metadata\"\n",
    "* use column 'Serie' as index\n",
    "* make sure you keep only the rows with data\n",
    "* set the variable distinct_scales with the number of ... distinct scales found in the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-017a7c31b0ddc38e",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Read file data/exercises/portugal_gas_emissions_per_year.xlsx with read_excel\n",
    "df6 = pd.read_excel(os.path.join('data', 'exercises', 'portugal_gas_emissions_per_year.xlsx'), sheet_name=\"Metadata\", skipfooter=6, skiprows=21, header=1, index_col='Serie')\n",
    "df6\n",
    "# YOUR CODE HERE\n",
    "\n",
    "distinct_scales = 2\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-91d5f07e40585680",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert distinct_scales == 2\n",
    "assert isinstance(df6, pd.DataFrame)\n",
    "expected_hash = '60c3ad36f77e7366103fe36a3f551a0cde7d64e26d3102ddb8b953d6208a6006'\n",
    "assert hashlib.sha256(\n",
    "        df6.loc[\n",
    "            df6.index==\"Nitrogen oxides\", \n",
    "            \"Measure Unit\"][0].encode()\n",
    "    ).hexdigest() == expected_hash\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4a7407517d4d92c3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Q7: Find the encoding of a file\n",
    "\n",
    "Find the encoding used in file **data/exercises/cities.csv**, using the method that was shown in the Learning Units.\n",
    "\n",
    "Then, read the data into a DataFrame, using the read_csv method and find the `City` characters that has distance equal to 7503."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bd6944fd63bb38d8",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Find the encoding of file data/exercises/mystery_cities.csv\n",
    "encoding = 'IBM866'\n",
    "chardet.detect(open(os.path.join('data', 'exercises', 'cities.csv'), 'rb').read())\n",
    "# YOUR CODE HERE\n",
    "# Read the file into a DataFrame\n",
    "df7 = pd.read_csv(os.path.join('data', 'exercises', 'cities.csv'), encoding='IBM866')\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Find the name of the city with distance = 7503\n",
    "city_found = df7.loc[3]['City']\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-687fb83c97e03355",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(df7, pd.DataFrame)\n",
    "\n",
    "expected_hash_1 = '969aef39a1d4cb1c5928c774cd7a4e3ccfc064a18fbd43a70193a2631d8a122d'\n",
    "assert hashlib.sha256(encoding.encode()).hexdigest() == expected_hash_1\n",
    "\n",
    "expected_hash_2 = '8086d7adc029756c1b9094df64f6e79017dcc5a99c3c5e55b47beede11179a2b'\n",
    "assert hashlib.sha256(city_found.encode()).hexdigest() == expected_hash_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d103dfae3d5e11fe",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Q8: Import a Random Sample of a Big File\n",
    "\n",
    "Consider the file **data/exercises/world_percentage_of_literacy.tsv**. Let's imagine this file is really huge, with a lot of rows!  Read the file using a random sample of 7 rows. Count the actual lines with `wc` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fb39107093dd73fb",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195\n"
     ]
    }
   ],
   "source": [
    "# Read file data/exercises/world_percentage_of_literacy.tsv with wc and save the number of lines\n",
    "# in lines_in_file. Notice that the header is not a line..\n",
    "# don't forget to close the opened file\n",
    "# YOUR CODE HERE\n",
    "! wc -l < data/exercises/world_percentage_of_literacy.tsv\n",
    "lines_in_file= 194\n",
    "\n",
    "# make parameter rows_to_skip equal to the lines you want to skip loading \n",
    "# don't forget: \n",
    "# - 7 rows should be fecthed)\n",
    "# - you want to keep the header plus 7 rows in the new dataframe...\n",
    "rows_to_skip = 187\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Create a df8 file with the sampled values\n",
    "n_rows_to_skip = lines_in_file - 7\n",
    "random.seed(42)\n",
    "rows_to_skip = random.sample(\n",
    "    range(1, lines_in_file-1), \n",
    "    n_rows_to_skip \n",
    ")\n",
    "df8 = pd.read_csv(os.path.join('data', 'exercises', 'world_percentage_of_literacy.tsv'), sep='\\t', skiprows=rows_to_skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-ec15a8be42137a01",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# getting remaining list of countries, removing rows_to_skip from the file\n",
    "df_helper = pd.read_csv( \n",
    "    'data/exercises/world_percentage_of_literacy.tsv', \n",
    "    sep='\\t',\n",
    "    header=0 \n",
    ")\n",
    "\n",
    "total_indexes = list(df_helper.index)\n",
    "for s in rows_to_skip:\n",
    "    total_indexes.remove(s-1)\n",
    "\n",
    "assert lines_in_file==194\n",
    "assert isinstance(df8, pd.DataFrame)\n",
    "assert list(df8['Country'])==list(df_helper.iloc[total_indexes]['Country'])\n",
    "assert df8.shape[0]==7\n",
    "\n",
    "expected_hash = '7902699be42c8a8e46fbbb4501726517e86b22c56a189f7625a6da49081b2451'\n",
    "assert  hashlib.sha256(str(df8.shape[0]).encode()).hexdigest() == expected_hash\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f87e07a7b2cacd9d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Q9: Loading a Big File\n",
    "\n",
    "Read file **data/exercises/world_percentage_of_literacy.tsv** using chunks keep only the columns `Country` and `Literacy rate (all)`.\n",
    "Note that:\n",
    "* file should be read by chunks of 10 countries\n",
    "* the missing values should be removed (filtered in each chunk)\n",
    "* the `Literacy rate (all)` should be converted to type float (in each chunk)\n",
    "* the index should be incremental starting from 0 (i.e, you don't need to read any column as the index)\n",
    "\n",
    "In the end calculate the average `Literacy rate (all)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Literacy rate (all)</th>\n",
       "      <th>Male literacy</th>\n",
       "      <th>Female literacy</th>\n",
       "      <th>Gender difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>World</td>\n",
       "      <td>86.3%</td>\n",
       "      <td>90.0%</td>\n",
       "      <td>82.7%</td>\n",
       "      <td>7.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>38.2%</td>\n",
       "      <td>52.0%</td>\n",
       "      <td>24.2%</td>\n",
       "      <td>27.8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Albania</td>\n",
       "      <td>97.6%</td>\n",
       "      <td>98.4%</td>\n",
       "      <td>96.8%</td>\n",
       "      <td>1.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>80.2%</td>\n",
       "      <td>87.2%</td>\n",
       "      <td>73.1%</td>\n",
       "      <td>14.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>not reported by UNESCO 2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Angola</td>\n",
       "      <td>71.1%</td>\n",
       "      <td>82.0%</td>\n",
       "      <td>60.7%</td>\n",
       "      <td>21.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Antigua and Barbuda</td>\n",
       "      <td>not reported by UNESCO 2015</td>\n",
       "      <td>99.0%(2013)[3][note 1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>98.1%</td>\n",
       "      <td>98.0%</td>\n",
       "      <td>98.1%</td>\n",
       "      <td>-0.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Armenia</td>\n",
       "      <td>99.8%</td>\n",
       "      <td>99.8%</td>\n",
       "      <td>99.7%</td>\n",
       "      <td>0.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Australia</td>\n",
       "      <td>not reported by UNESCO 2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Austria</td>\n",
       "      <td>not reported by UNESCO 2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Azerbaijan</td>\n",
       "      <td>99.8%</td>\n",
       "      <td>99.9%</td>\n",
       "      <td>99.7%</td>\n",
       "      <td>0.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Bahamas</td>\n",
       "      <td>not reported by UNESCO 2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Bahrain</td>\n",
       "      <td>95.7%</td>\n",
       "      <td>96.9%</td>\n",
       "      <td>93.5%</td>\n",
       "      <td>3.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>72.8%[note 2]</td>\n",
       "      <td>75.6%</td>\n",
       "      <td>69.9%</td>\n",
       "      <td>5.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Barbados</td>\n",
       "      <td>not reported by UNESCO 2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Belarus</td>\n",
       "      <td>99.7%</td>\n",
       "      <td>99.8%</td>\n",
       "      <td>99.7%</td>\n",
       "      <td>0.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Belgium</td>\n",
       "      <td>not reported by UNESCO 2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Belize</td>\n",
       "      <td>82.7%</td>\n",
       "      <td>82.3%</td>\n",
       "      <td>83.0%</td>\n",
       "      <td>-0.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Benin</td>\n",
       "      <td>38.4%</td>\n",
       "      <td>49.9%</td>\n",
       "      <td>27.3%</td>\n",
       "      <td>22.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Bhutan</td>\n",
       "      <td>64.9%</td>\n",
       "      <td>73.1%</td>\n",
       "      <td>55.0%</td>\n",
       "      <td>18.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Bolivia</td>\n",
       "      <td>95.7%</td>\n",
       "      <td>97.8%</td>\n",
       "      <td>93.6%</td>\n",
       "      <td>4.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Bosnia and Herzegovina</td>\n",
       "      <td>98.5%</td>\n",
       "      <td>99.5%</td>\n",
       "      <td>97.5%</td>\n",
       "      <td>2.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Botswana</td>\n",
       "      <td>88.5%</td>\n",
       "      <td>88.0%</td>\n",
       "      <td>88.9%</td>\n",
       "      <td>-0.9%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Brazil</td>\n",
       "      <td>91.7%</td>\n",
       "      <td>91.4%</td>\n",
       "      <td>92.1%</td>\n",
       "      <td>-0.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Brunei</td>\n",
       "      <td>96.4%</td>\n",
       "      <td>97.7%</td>\n",
       "      <td>95.1%</td>\n",
       "      <td>2.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Bulgaria</td>\n",
       "      <td>98.4%</td>\n",
       "      <td>98.7%</td>\n",
       "      <td>98.1%</td>\n",
       "      <td>0.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Burkina Faso</td>\n",
       "      <td>36%</td>\n",
       "      <td>43.0%</td>\n",
       "      <td>29.3%</td>\n",
       "      <td>13.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Burundi</td>\n",
       "      <td>85.6%</td>\n",
       "      <td>88.2%</td>\n",
       "      <td>83.1%</td>\n",
       "      <td>5.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Cabo Verde</td>\n",
       "      <td>87.6%</td>\n",
       "      <td>92.1%</td>\n",
       "      <td>83.1%</td>\n",
       "      <td>9.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>Sudan</td>\n",
       "      <td>53.5%</td>\n",
       "      <td>59.80%</td>\n",
       "      <td>46.7%</td>\n",
       "      <td>13.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>Suriname</td>\n",
       "      <td>95.6%</td>\n",
       "      <td>96.1%</td>\n",
       "      <td>95.0%</td>\n",
       "      <td>1.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>Swaziland</td>\n",
       "      <td>87.5%</td>\n",
       "      <td>87.4%</td>\n",
       "      <td>87.5%</td>\n",
       "      <td>-0.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>Sweden</td>\n",
       "      <td>not reported by UNESCO 2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>Switzerland</td>\n",
       "      <td>not reported by UNESCO 2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>Syria</td>\n",
       "      <td>86.4%</td>\n",
       "      <td>91.7%</td>\n",
       "      <td>81.0%</td>\n",
       "      <td>10.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>Tajikistan</td>\n",
       "      <td>99.8%</td>\n",
       "      <td>99.8%</td>\n",
       "      <td>99.7%</td>\n",
       "      <td>0.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>Tanzania, United Republic of</td>\n",
       "      <td>80.3%</td>\n",
       "      <td>84.8%</td>\n",
       "      <td>75.9%</td>\n",
       "      <td>9.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>Thailand</td>\n",
       "      <td>96.7%</td>\n",
       "      <td>96.6%</td>\n",
       "      <td>96.7%</td>\n",
       "      <td>-0.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>Timor-Leste</td>\n",
       "      <td>67.5%</td>\n",
       "      <td>71.5%</td>\n",
       "      <td>63.4%</td>\n",
       "      <td>8.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>Togo</td>\n",
       "      <td>66.5%</td>\n",
       "      <td>78.3%</td>\n",
       "      <td>55.3%</td>\n",
       "      <td>23.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>Tonga</td>\n",
       "      <td>99.4%</td>\n",
       "      <td>99.3%</td>\n",
       "      <td>99.4%</td>\n",
       "      <td>-0.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>Trinidad and Tobago</td>\n",
       "      <td>99%</td>\n",
       "      <td>99.2%</td>\n",
       "      <td>98.7%</td>\n",
       "      <td>0.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>Tunisia</td>\n",
       "      <td>81.8%</td>\n",
       "      <td>89.6%</td>\n",
       "      <td>74.2%</td>\n",
       "      <td>15.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>Turkey</td>\n",
       "      <td>95%</td>\n",
       "      <td>98.4%</td>\n",
       "      <td>91.8%</td>\n",
       "      <td>6.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>Turkmenistan</td>\n",
       "      <td>99.7%</td>\n",
       "      <td>99.8%</td>\n",
       "      <td>99.6%</td>\n",
       "      <td>0.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>Tuvalu</td>\n",
       "      <td>not reported by UNESCO 2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>Uganda</td>\n",
       "      <td>73.9%</td>\n",
       "      <td>80.8%</td>\n",
       "      <td>66.9%</td>\n",
       "      <td>14.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>Ukraine</td>\n",
       "      <td>99.8%</td>\n",
       "      <td>99.8%</td>\n",
       "      <td>99.7%</td>\n",
       "      <td>0.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>93.8%</td>\n",
       "      <td>93.1%</td>\n",
       "      <td>95.8%</td>\n",
       "      <td>-2.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>not reported by UNESCO 2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>United States of America</td>\n",
       "      <td>not reported by UNESCO 2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>Uruguay</td>\n",
       "      <td>98.4%</td>\n",
       "      <td>98.1%</td>\n",
       "      <td>98.7%</td>\n",
       "      <td>-0.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>Uzbekistan</td>\n",
       "      <td>99.6%</td>\n",
       "      <td>99.7%</td>\n",
       "      <td>99.5%</td>\n",
       "      <td>0.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>Vanuatu</td>\n",
       "      <td>85.2%</td>\n",
       "      <td>86.6%</td>\n",
       "      <td>83.8%</td>\n",
       "      <td>2.8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>Venezuela</td>\n",
       "      <td>95.4%</td>\n",
       "      <td>95.0%</td>\n",
       "      <td>95.7%</td>\n",
       "      <td>-0.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>Vietnam</td>\n",
       "      <td>94.5%</td>\n",
       "      <td>96.3%</td>\n",
       "      <td>92.8%</td>\n",
       "      <td>3.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>Yemen</td>\n",
       "      <td>70.1%</td>\n",
       "      <td>85.1%</td>\n",
       "      <td>55.0%</td>\n",
       "      <td>30.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>63.4%</td>\n",
       "      <td>70.9%</td>\n",
       "      <td>56.0%</td>\n",
       "      <td>14.9%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>86.5%</td>\n",
       "      <td>88.5%</td>\n",
       "      <td>84.6%</td>\n",
       "      <td>4.0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>194 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Country          Literacy rate (all)  \\\n",
       "0                           World                        86.3%   \n",
       "1                     Afghanistan                        38.2%   \n",
       "2                         Albania                        97.6%   \n",
       "3                         Algeria                        80.2%   \n",
       "4                         Andorra  not reported by UNESCO 2015   \n",
       "5                          Angola                        71.1%   \n",
       "6             Antigua and Barbuda  not reported by UNESCO 2015   \n",
       "7                       Argentina                        98.1%   \n",
       "8                         Armenia                        99.8%   \n",
       "9                       Australia  not reported by UNESCO 2015   \n",
       "10                        Austria  not reported by UNESCO 2015   \n",
       "11                     Azerbaijan                        99.8%   \n",
       "12                        Bahamas  not reported by UNESCO 2015   \n",
       "13                        Bahrain                        95.7%   \n",
       "14                     Bangladesh                72.8%[note 2]   \n",
       "15                       Barbados  not reported by UNESCO 2015   \n",
       "16                        Belarus                        99.7%   \n",
       "17                        Belgium  not reported by UNESCO 2015   \n",
       "18                         Belize                        82.7%   \n",
       "19                          Benin                        38.4%   \n",
       "20                         Bhutan                        64.9%   \n",
       "21                        Bolivia                        95.7%   \n",
       "22         Bosnia and Herzegovina                        98.5%   \n",
       "23                       Botswana                        88.5%   \n",
       "24                         Brazil                        91.7%   \n",
       "25                         Brunei                        96.4%   \n",
       "26                       Bulgaria                        98.4%   \n",
       "27                   Burkina Faso                          36%   \n",
       "28                        Burundi                        85.6%   \n",
       "29                     Cabo Verde                        87.6%   \n",
       "..                            ...                          ...   \n",
       "164                         Sudan                        53.5%   \n",
       "165                      Suriname                        95.6%   \n",
       "166                     Swaziland                        87.5%   \n",
       "167                        Sweden  not reported by UNESCO 2015   \n",
       "168                   Switzerland  not reported by UNESCO 2015   \n",
       "169                         Syria                        86.4%   \n",
       "170                    Tajikistan                        99.8%   \n",
       "171  Tanzania, United Republic of                        80.3%   \n",
       "172                      Thailand                        96.7%   \n",
       "173                   Timor-Leste                        67.5%   \n",
       "174                          Togo                        66.5%   \n",
       "175                         Tonga                        99.4%   \n",
       "176           Trinidad and Tobago                          99%   \n",
       "177                       Tunisia                        81.8%   \n",
       "178                        Turkey                          95%   \n",
       "179                  Turkmenistan                        99.7%   \n",
       "180                        Tuvalu  not reported by UNESCO 2015   \n",
       "181                        Uganda                        73.9%   \n",
       "182                       Ukraine                        99.8%   \n",
       "183          United Arab Emirates                        93.8%   \n",
       "184                United Kingdom  not reported by UNESCO 2015   \n",
       "185      United States of America  not reported by UNESCO 2015   \n",
       "186                       Uruguay                        98.4%   \n",
       "187                    Uzbekistan                        99.6%   \n",
       "188                       Vanuatu                        85.2%   \n",
       "189                     Venezuela                        95.4%   \n",
       "190                       Vietnam                        94.5%   \n",
       "191                         Yemen                        70.1%   \n",
       "192                        Zambia                        63.4%   \n",
       "193                      Zimbabwe                        86.5%   \n",
       "\n",
       "              Male literacy Female literacy Gender difference  \n",
       "0                     90.0%           82.7%              7.3%  \n",
       "1                     52.0%           24.2%             27.8%  \n",
       "2                     98.4%           96.8%              1.6%  \n",
       "3                     87.2%           73.1%             14.0%  \n",
       "4                       NaN             NaN               NaN  \n",
       "5                     82.0%           60.7%             21.3%  \n",
       "6    99.0%(2013)[3][note 1]             NaN               NaN  \n",
       "7                     98.0%           98.1%             -0.1%  \n",
       "8                     99.8%           99.7%              0.1%  \n",
       "9                       NaN             NaN               NaN  \n",
       "10                      NaN             NaN               NaN  \n",
       "11                    99.9%           99.7%              0.2%  \n",
       "12                      NaN             NaN               NaN  \n",
       "13                    96.9%           93.5%              3.5%  \n",
       "14                    75.6%           69.9%              5.7%  \n",
       "15                      NaN             NaN               NaN  \n",
       "16                    99.8%           99.7%              0.1%  \n",
       "17                      NaN             NaN               NaN  \n",
       "18                    82.3%           83.0%             -0.7%  \n",
       "19                    49.9%           27.3%             22.6%  \n",
       "20                    73.1%           55.0%             18.1%  \n",
       "21                    97.8%           93.6%              4.2%  \n",
       "22                    99.5%           97.5%              2.1%  \n",
       "23                    88.0%           88.9%             -0.9%  \n",
       "24                    91.4%           92.1%             -0.7%  \n",
       "25                    97.7%           95.1%              2.6%  \n",
       "26                    98.7%           98.1%              0.7%  \n",
       "27                    43.0%           29.3%             13.7%  \n",
       "28                    88.2%           83.1%              5.1%  \n",
       "29                    92.1%           83.1%              9.0%  \n",
       "..                      ...             ...               ...  \n",
       "164                  59.80%           46.7%             13.1%  \n",
       "165                   96.1%           95.0%              1.1%  \n",
       "166                   87.4%           87.5%             -0.1%  \n",
       "167                     NaN             NaN               NaN  \n",
       "168                     NaN             NaN               NaN  \n",
       "169                   91.7%           81.0%             10.7%  \n",
       "170                   99.8%           99.7%              0.1%  \n",
       "171                   84.8%           75.9%              9.0%  \n",
       "172                   96.6%           96.7%             -0.1%  \n",
       "173                   71.5%           63.4%              8.1%  \n",
       "174                   78.3%           55.3%             23.0%  \n",
       "175                   99.3%           99.4%             -0.1%  \n",
       "176                   99.2%           98.7%              0.5%  \n",
       "177                   89.6%           74.2%             15.4%  \n",
       "178                   98.4%           91.8%              6.6%  \n",
       "179                   99.8%           99.6%              0.1%  \n",
       "180                     NaN             NaN               NaN  \n",
       "181                   80.8%           66.9%             14.0%  \n",
       "182                   99.8%           99.7%              0.1%  \n",
       "183                   93.1%           95.8%             -2.6%  \n",
       "184                     NaN             NaN               NaN  \n",
       "185                     NaN             NaN               NaN  \n",
       "186                   98.1%           98.7%             -0.6%  \n",
       "187                   99.7%           99.5%              0.3%  \n",
       "188                   86.6%           83.8%              2.8%  \n",
       "189                   95.0%           95.7%             -0.7%  \n",
       "190                   96.3%           92.8%              3.4%  \n",
       "191                   85.1%           55.0%             30.1%  \n",
       "192                   70.9%           56.0%             14.9%  \n",
       "193                   88.5%           84.6%              4.0%  \n",
       "\n",
       "[194 rows x 5 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(os.path.join('data', 'exercises', 'world_percentage_of_literacy.tsv'), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5106c25a705296e8",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-109-5a3192ebb8aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdata_chunk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mchunks_iter\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m     \u001b[0mdata_chunk_filtered\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloatifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_chunk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m     \u001b[0mchunk_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_chunk_filtered\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[0mdf9\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-109-5a3192ebb8aa>\u001b[0m in \u001b[0;36mfloatifier\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfloatifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"not reported by UNESCO 2015\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Literacy rate (all)\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\blu01\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5065\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5066\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5067\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5069\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'name'"
     ]
    }
   ],
   "source": [
    "# Read file data/exercises/world_percentage_of_literacy.tsv\n",
    "# the chunks should be appended in a list called \n",
    "\n",
    "chunks_iter = pd.read_csv(os.path.join('data', 'exercises', 'world_percentage_of_literacy.tsv'),sep='\\t', chunksize=10, usecols= ['Country', 'Literacy rate (all)'])\n",
    "chunk_arr = []\n",
    "\n",
    "# df9 should be the final dataframe with concatenated chunks\n",
    "# Resulting average should go on lit_avg variable\n",
    "# YOUR CODE HERE\n",
    "def __repr__(self):\n",
    "    return str(self.__dict__)\n",
    "\n",
    "def floatifier(data):\n",
    "    \n",
    "    data = data[data.name != \"not reported by UNESCO 2015\"]\n",
    "    a = data[\"Literacy rate (all)\"].tolist()\n",
    "    for x, y in zip(range(len(a)), a):\n",
    "        if len(y) == 3:\n",
    "            y = y[:2]\n",
    "            a[x] = y\n",
    "        elif len(y) == 5:\n",
    "            y = y[:4]\n",
    "            a[x] = y\n",
    "        if \"[note 2]\" in y:\n",
    "            y = y.replace(\"[note 2]\", \"\")\n",
    "            a[x] = y\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "            \n",
    "    \n",
    "        \n",
    "            \n",
    "    \n",
    "        \n",
    "    return data\n",
    "\n",
    "for data_chunk in chunks_iter:\n",
    "    data_chunk_filtered = floatifier(data_chunk)\n",
    "    chunk_arr.append(data_chunk_filtered)\n",
    "df9= pd.concat(chunk_arr, axis=0)\n",
    "lit_avg=df9['Literacy rate (all)'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-f60a22c3465d5b83",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert df9.loc[df9['Country']=='World', 'Literacy rate (all)'].values[0] == 86.3\n",
    "assert df9.dtypes['Country'] == np.object\n",
    "assert df9.dtypes['Literacy rate (all)'] == np.float\n",
    "\n",
    "expected_hash = 'f26cd8ca964afd7aaaea0cacb142419676cf9928772f5b5310a036ffdae1586a'\n",
    "assert hashlib.sha256(str([len(c) for c in chunk_arr]).encode()).hexdigest() == expected_hash\n",
    "\n",
    "expected_hash = '94f2bba3a658b5642ebbc9b952af45c3db1a185ae0357e4fe7ced784f0c3fe29'\n",
    "assert hashlib.sha256(str(lit_avg).encode()).hexdigest() == expected_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e990312f7cddd0b2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Q10: Calculate average values using chunks and avoiding a complete data frame in memory.\n",
    "\n",
    "Using chunks, read file **data/exercises/world_percentage_of_literacy.tsv**, avoid incompleted rows and calculate the average of ***Literacy rate (all)*** without loading all data simultaneously. Use a similar approach of the previous question but don't create any dataframe neither any list with chunks;\n",
    "\n",
    "***Hint: Use the average definition***\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-57fd7700885246eb",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Read file data/exercises/world_percentage_of_literacy.tsv\n",
    "# the final average should be in the variable final_avg\n",
    "# You should increment 2 variables in each chunk and use them at the end to calculate final_avg. call them lit_a, lit_b\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-0edcf1260d7886c9",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert math.isclose(83.24370860927154, final_avg, rel_tol=1e-1)\n",
    "assert lit_b==151 or lit_a==151\n",
    "assert int(lit_b) == 12569 or int(lit_a)==12569"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
